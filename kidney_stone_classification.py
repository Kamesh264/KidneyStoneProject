# -*- coding: utf-8 -*-
"""Kidney Stone Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rflctZVulMpAqKRWUeYu77B8sHrGSaV9

# Data Acquisition
"""

#installing Kaggle
# !pip install -q kaggle

# # uploading the json file
# from google.colab import files
# files.upload()

# #create a kaggle directory
# ! mkdir ~/.kaggle

# #copy the kaggle.json to folder created
# ! cp kaggle.json ~/.kaggle

# #changing permissions
# ! chmod 600 ~/.kaggle/kaggle.json

# !kaggle datasets list

# #downloading the dataset
# !kaggle datasets download -d nazmul0087/ct-kidney-dataset-normal-cyst-tumor-and-stone

# # extracting the zipfile
# !unzip ct-kidney-dataset-normal-cyst-tumor-and-stone

"""# Data Exploration"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
import cv2
from pathlib import Path
import seaborn as sns
import matplotlib.pyplot as plt
from skimage.io import imread

import os
os.listdir('/content/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone')

os.listdir('/content/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone')

path_main = '/content/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone'
for folder in os.listdir(path_main):
    list_of_elements = os.listdir(os.path.join(path_main, folder))
    print(f'Folder: {folder}\n')
    print(f'Number of elements: {len(list_of_elements)}\n')
    print(f'First item\'s name: {list_of_elements[0]}\n')
    print('*'*50)

def plot_imgs(item_dir, num_imgs=25):
    all_item_dirs = os.listdir(item_dir)
    item_files = [os.path.join(item_dir, file) for file in all_item_dirs][:num_imgs]

    plt.figure(figsize=(10, 10))
    for idx, img_path in enumerate(item_files):
        plt.subplot(5, 5, idx+1)
        img = plt.imread(img_path)
        plt.title(f'{img_path}'[-10:-4])
        plt.imshow(img)

    plt.tight_layout()

path_cyst = '/content/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/Cyst'
path_normal = '/content/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/Normal'
path_stone = '/content/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/Stone'
path_tumor = '/content/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/Tumor'

"""## Cyst"""

plot_imgs(path_cyst,10)

"""## Normal"""

plot_imgs(path_normal,10)

"""## Stone"""

plot_imgs(path_stone, 10)

"""## Tumor"""

plot_imgs(path_tumor,10)

"""# Splitting Data into Training and Testing sets"""

# !pip install split-folders

import splitfolders
splitfolders.ratio(
    "../content/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone",
   output="./dataset",
   seed=7,
   ratio=(0.8,0.1, 0.1)
)

"""# Data Transformation"""

from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale=1/255)
valid_datagen = ImageDataGenerator(rescale=1/255)
test_datagen = ImageDataGenerator(rescale=1/255)



"""# Dataset Loading"""

train_dataset = train_datagen.flow_from_directory('./dataset/train',
                                                  target_size=(200, 200),
                                                  color_mode='grayscale',
                                                  class_mode='categorical',
                                                  batch_size=100,
                                                  )

test_dataset = test_datagen.flow_from_directory('./dataset/test',
                                                target_size=(200, 200),
                                                class_mode='categorical',
                                                color_mode='grayscale',
                                                batch_size=100,
                                                shuffle=False
                                                )

valid_dataset = valid_datagen.flow_from_directory('./dataset/val',
                                                  target_size=(200, 200),
                                                  class_mode='categorical',
                                                  batch_size=100,
                                                  color_mode='grayscale',
                                                  )

# for i in valid_dataset:
#   print(type(i))
valid_dataset[0][0]

len_testdataset = len(test_dataset)
for i in range(2):
    batch = test_dataset[i]

    # if batch is made of x and y: #this line is pseudocode
    x, y = batch
    print(x.shape)
    print(y.shape)
    # x = np.clip(x, a_min=None, a_max=2*100)
    # y = np.clip(y, a_min=None, a_max=2*100)
    # if batch has only x: #this line is peudocode
    #     x = batch
    for i in range(10):
      # Extract an image from x
      image = x[i, :, :, 0]  # Assuming it's grayscale

      # Extract any relevant information from y
      info = y[i]

      # Display the image and information
      plt.figure()
      plt.imshow(image, cmap='gray')  # Adjust the colormap if needed
      plt.title(f"Image {i+1}")

      # Print any relevant information from y
      print(f"Info for Image {i+1}: {info}")

      # Show the plot
      plt.show()

"""# Model"""

from keras.models import Sequential
from keras.layers import Conv2D, Flatten, MaxPooling2D, Dense

from keras import models
from keras import layers

train_dataset.image_shape

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(200, 200, 1)),
    MaxPooling2D(pool_size=(2, 2), padding='same', name='maxPool_1'),

    Conv2D(64, (3, 3), padding='same', activation='relu'),
    MaxPooling2D(pool_size=(2, 2), padding='same', name='maxPool_2'),

    Conv2D(128, (3, 3), padding='same', activation='relu'),
    MaxPooling2D(pool_size=(2, 2), padding='same', name='maxPool_3'),

    Conv2D(256, (3, 3), padding='same', activation='relu'),
    MaxPooling2D(pool_size=(2, 2), padding='same', name='maxPool_4'),

    Conv2D(512, (3, 3), padding='same', activation='relu'),
    MaxPooling2D(pool_size=(2, 2), padding='same', name='maxPool_5'),

    Conv2D(256, (3, 3), padding='same', activation='relu'),
    MaxPooling2D(pool_size=(2, 2), padding='same', name='maxPool_6'),

    Conv2D(128, (3, 3), padding='same', activation='relu'),
    MaxPooling2D(pool_size=(2, 2), padding='same', name='maxPool_7'),
    Conv2D(64, (3, 3), padding='same', activation='relu'),
    MaxPooling2D(pool_size=(2, 2), padding='same', name='maxPool_8'),

    Conv2D(32, (3, 3), padding='same', activation='relu'),
    MaxPooling2D(pool_size=(2, 2), padding='same', name='maxPool_9'),

    Flatten(),

    Dense(128, activation='relu', name='dense__1'),
    Dense(64, activation='relu'),
    Dense(4, activation='softmax')
])

import keras
METRICS = [
        'accuracy',
        keras.metrics.Precision(name='precision'),
        keras.metrics.Recall(name='recall')
    ]

model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=METRICS)

from tensorflow.keras.callbacks import ModelCheckpoint

checkpoint = ModelCheckpoint('model_checkpoint.h5',
                             monitor='val_loss',
                             save_best_only=True)

model_fit = model.fit(train_dataset,
                      validation_data=valid_dataset,
                      steps_per_epoch = 3,
                      epochs = 5,
                      callbacks=[checkpoint])

from tensorflow.keras.callbacks import ModelCheckpoint



fig, ax = plt.subplots(1, 4, figsize=(20, 3))
ax = ax.ravel()

for i, met in enumerate(['precision', 'recall', 'accuracy', 'loss']):
    ax[i].plot(model_fit.history[met])
    ax[i].plot(model_fit.history['val_' + met])
    ax[i].set_title('Model {}'.format(met))
    ax[i].set_xlabel('epochs')
    ax[i].set_ylabel(met)
    ax[i].legend(['train', 'val'])

predictions = model.predict(test_dataset)
print(predictions)

diseases_labels = []

for key, value in train_dataset.class_indices.items():
   diseases_labels.append(key)

"""# Evaluation"""

from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_recall_fscore_support
import seaborn as sns

def evaluate(actual, predictions):
  pre = []
  for i in predictions:
    pre.append(np.argmax(i))

  accuracy = (pre == actual).sum() / actual.shape[0]
  print(f'Accuracy: {accuracy}')

  precision, recall, f1_score, _ = precision_recall_fscore_support(actual, pre, average='macro')
  print(f'Precision: {precision}')
  print(f'Recall: {recall}')
  print(f'F1_score: {f1_score}')

  fig, ax = plt.subplots(figsize=(20,20))
  conf_mat = confusion_matrix(actual, pre)
  sns.heatmap(conf_mat, annot=True, fmt='.0f', cmap="YlGnBu", xticklabels=diseases_labels, yticklabels=diseases_labels).set_title('Confusion Matrix Heat map')
  plt.show()

evaluate(test_dataset.classes,predictions)

model.evaluate(test_dataset)

model.save('model.h5')

import tensorflow as tf

savedmodel= tf.keras.models.load_model("model.h5")
fpredictions = savedmodel.predict(test_dataset)

fpredictions



fpre = []
for i in fpredictions:
  j=np.argmax(i)
  if(j==0):
    fpre.append("Cyst")
  if(j==0):
    fpre.append("Normal")
  if(j==0):
    fpre.append("Stone")
  if(j==0):
    fpre.append("Tumor")
fpre

from PIL import Image
import numpy as np
from tensorflow import keras
import cv2
# Load and resize the image
# image_path = '/content/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/Cyst/Cyst- (1842).jpg'
image_path = '/content/test_kidney_stone_1.jpg'
target_size = (200, 200)  # Specify the desired size for the image

# Open the image using PIL
image = Image.open(image_path)
print(image.size)
gray_image = cv2.imread(image_path)
num_channels = gray_image.shape[2]
print(num_channels)
# Resize the image while maintaining the aspect ratio
# image = image.resize(target_size)

# Convert the image to a NumPy array
# image_array = np.array(image)
# print(image_array.shape)
# image_array = image_array.reshape((200, 200, 1))
# print(image_array.shape)
if num_channels == 3:
  gray_image = cv2.cvtColor(cv2.resize(gray_image, (200, 200)), cv2.COLOR_BGR2GRAY)

  gray_image = np.expand_dims(gray_image, axis=-1)
  gray_image = gray_image / 255.0
print('gray_image size = ',gray_image.shape)
# Load the model
model = keras.models.load_model('model.h5')

obj_list = ['Normal', 'Tumor', 'Cyst', 'Stone']
# Perform inference on the preprocessed image
predictions = model.predict(np.expand_dims(gray_image, axis=0))
print(type(predictions))
print(predictions)
print(obj_list[np.argmax(predictions)])

import pickle
pickle.dump(model, open("Kidney_Stone.pkl",'wb'))

model.save('model_dl.h5')

